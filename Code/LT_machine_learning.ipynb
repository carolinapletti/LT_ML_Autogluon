{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LT Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze with auto-ML Laughing Together data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import and prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will have this format: \n",
    "- features:\n",
    "    - for each participant and each interval, coherence for each channel combination (one value per channel combination - 10 in total)\n",
    "    - list of intervals (1 for video 1, 2 for video 2, 3 for interaction 1 and 4 for interaction 5)\n",
    "    - liking pre (average of scores)\n",
    "    - laughter group (laughter, control)\n",
    "    - interaction group (interaction, control)\n",
    "    - age\n",
    "    - gender\n",
    "- outcome:\n",
    "    - liking post (average of scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 General settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set random seed for replicability\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set coherence data folder\n",
    "coherence_folder = \"Z:/projects/LT/LT_adults/Carolina_analyses/fNIRS/data_prep/data\"\n",
    "\n",
    "# Set data folder where the rest is saved\n",
    "data_path = \"Y:/Documents/Projects/LT_machine_learning/Data\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Coherence data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Coherence during videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IFGr_IFGr</th>\n",
       "      <th>IFGr_IFGl</th>\n",
       "      <th>IFGr_TPJr</th>\n",
       "      <th>IFGr_TPJl</th>\n",
       "      <th>IFGl_IFGr</th>\n",
       "      <th>IFGl_IFGl</th>\n",
       "      <th>IFGl_TPJr</th>\n",
       "      <th>IFGl_TPJl</th>\n",
       "      <th>TPJr_IFGr</th>\n",
       "      <th>TPJr_IFGl</th>\n",
       "      <th>TPJr_TPJr</th>\n",
       "      <th>TPJr_TPJl</th>\n",
       "      <th>TPJl_IFGr</th>\n",
       "      <th>TPJl_IFGl</th>\n",
       "      <th>TPJl_TPJr</th>\n",
       "      <th>TPJl_TPJl</th>\n",
       "      <th>Interval</th>\n",
       "      <th>Pair</th>\n",
       "      <th>Group</th>\n",
       "      <th>Segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.253717</td>\n",
       "      <td>0.276044</td>\n",
       "      <td>0.258718</td>\n",
       "      <td>0.285384</td>\n",
       "      <td>0.249407</td>\n",
       "      <td>0.215108</td>\n",
       "      <td>0.214340</td>\n",
       "      <td>0.219691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>IC</td>\n",
       "      <td>laughter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.231923</td>\n",
       "      <td>0.289607</td>\n",
       "      <td>0.239531</td>\n",
       "      <td>0.248008</td>\n",
       "      <td>0.232951</td>\n",
       "      <td>0.288870</td>\n",
       "      <td>0.260857</td>\n",
       "      <td>0.253972</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>IC</td>\n",
       "      <td>laughter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.229439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.198435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.211421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.229041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>IC</td>\n",
       "      <td>laughter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.453068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.422309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.217067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.174231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>IC</td>\n",
       "      <td>laughter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.288269</td>\n",
       "      <td>0.257061</td>\n",
       "      <td>0.267321</td>\n",
       "      <td>0.274450</td>\n",
       "      <td>0.352842</td>\n",
       "      <td>0.303648</td>\n",
       "      <td>0.305565</td>\n",
       "      <td>0.343827</td>\n",
       "      <td>0.187786</td>\n",
       "      <td>0.294686</td>\n",
       "      <td>0.193177</td>\n",
       "      <td>0.183882</td>\n",
       "      <td>0.194623</td>\n",
       "      <td>0.247054</td>\n",
       "      <td>0.233287</td>\n",
       "      <td>0.187955</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>IC</td>\n",
       "      <td>laughter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IFGr_IFGr  IFGr_IFGl  IFGr_TPJr  IFGr_TPJl  IFGl_IFGr  IFGl_IFGl  \\\n",
       "0   0.253717   0.276044   0.258718   0.285384   0.249407   0.215108   \n",
       "1   0.231923   0.289607   0.239531   0.248008   0.232951   0.288870   \n",
       "2        NaN   0.229439        NaN        NaN        NaN   0.198435   \n",
       "3        NaN   0.453068        NaN        NaN        NaN   0.422309   \n",
       "4   0.288269   0.257061   0.267321   0.274450   0.352842   0.303648   \n",
       "\n",
       "   IFGl_TPJr  IFGl_TPJl  TPJr_IFGr  TPJr_IFGl  TPJr_TPJr  TPJr_TPJl  \\\n",
       "0   0.214340   0.219691        NaN        NaN        NaN        NaN   \n",
       "1   0.260857   0.253972        NaN        NaN        NaN        NaN   \n",
       "2        NaN        NaN        NaN   0.211421        NaN        NaN   \n",
       "3        NaN        NaN        NaN   0.217067        NaN        NaN   \n",
       "4   0.305565   0.343827   0.187786   0.294686   0.193177   0.183882   \n",
       "\n",
       "   TPJl_IFGr  TPJl_IFGl  TPJl_TPJr  TPJl_TPJl  Interval  Pair Group   Segment  \n",
       "0        NaN        NaN        NaN        NaN         1     1    IC  laughter  \n",
       "1        NaN        NaN        NaN        NaN         2     1    IC  laughter  \n",
       "2        NaN   0.229041        NaN        NaN         1     2    IC  laughter  \n",
       "3        NaN   0.174231        NaN        NaN         2     2    IC  laughter  \n",
       "4   0.194623   0.247054   0.233287   0.187955         1     3    IC  laughter  "
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load video data\n",
    "\n",
    "video_filename = coherence_folder + \"/Data_ROI_laughter_all.csv\"\n",
    "df = pd.read_csv(video_filename)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 199 entries, 0 to 198\n",
      "Data columns (total 20 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   IFGr_IFGr  177 non-null    float64\n",
      " 1   IFGr_IFGl  190 non-null    float64\n",
      " 2   IFGr_TPJr  155 non-null    float64\n",
      " 3   IFGr_TPJl  162 non-null    float64\n",
      " 4   IFGl_IFGr  184 non-null    float64\n",
      " 5   IFGl_IFGl  197 non-null    float64\n",
      " 6   IFGl_TPJr  160 non-null    float64\n",
      " 7   IFGl_TPJl  167 non-null    float64\n",
      " 8   TPJr_IFGr  155 non-null    float64\n",
      " 9   TPJr_IFGl  168 non-null    float64\n",
      " 10  TPJr_TPJr  133 non-null    float64\n",
      " 11  TPJr_TPJl  141 non-null    float64\n",
      " 12  TPJl_IFGr  148 non-null    float64\n",
      " 13  TPJl_IFGl  161 non-null    float64\n",
      " 14  TPJl_TPJr  127 non-null    float64\n",
      " 15  TPJl_TPJl  135 non-null    float64\n",
      " 16  Interval   199 non-null    int64  \n",
      " 17  Pair       199 non-null    int64  \n",
      " 18  Group      199 non-null    object \n",
      " 19  Segment    199 non-null    object \n",
      "dtypes: float64(16), int64(2), object(2)\n",
      "memory usage: 31.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pair</th>\n",
       "      <th>Group</th>\n",
       "      <th>Segment</th>\n",
       "      <th>Interval</th>\n",
       "      <th>IFGr_IFGr</th>\n",
       "      <th>IFGl_IFGl</th>\n",
       "      <th>TPJr_TPJr</th>\n",
       "      <th>TPJl_TPJl</th>\n",
       "      <th>IFGl_IFGr</th>\n",
       "      <th>IFGr_TPJr</th>\n",
       "      <th>IFGr_TPJl</th>\n",
       "      <th>IFGl_TPJr</th>\n",
       "      <th>IFGl_TPJl</th>\n",
       "      <th>TPJr_TPJl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>IC</td>\n",
       "      <td>laughter</td>\n",
       "      <td>1</td>\n",
       "      <td>0.253717</td>\n",
       "      <td>0.215108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.262726</td>\n",
       "      <td>0.258718</td>\n",
       "      <td>0.285384</td>\n",
       "      <td>0.214340</td>\n",
       "      <td>0.219691</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>IC</td>\n",
       "      <td>laughter</td>\n",
       "      <td>2</td>\n",
       "      <td>0.231923</td>\n",
       "      <td>0.288870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.261279</td>\n",
       "      <td>0.239531</td>\n",
       "      <td>0.248008</td>\n",
       "      <td>0.260857</td>\n",
       "      <td>0.253972</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>IC</td>\n",
       "      <td>laughter</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.198435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.229439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.211421</td>\n",
       "      <td>0.229041</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>IC</td>\n",
       "      <td>laughter</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.422309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.453068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.217067</td>\n",
       "      <td>0.174231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>IC</td>\n",
       "      <td>laughter</td>\n",
       "      <td>1</td>\n",
       "      <td>0.288269</td>\n",
       "      <td>0.303648</td>\n",
       "      <td>0.193177</td>\n",
       "      <td>0.187955</td>\n",
       "      <td>0.304951</td>\n",
       "      <td>0.227554</td>\n",
       "      <td>0.234536</td>\n",
       "      <td>0.300126</td>\n",
       "      <td>0.295440</td>\n",
       "      <td>0.208585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pair Group   Segment  Interval  IFGr_IFGr  IFGl_IFGl  TPJr_TPJr  TPJl_TPJl  \\\n",
       "0     1    IC  laughter         1   0.253717   0.215108        NaN        NaN   \n",
       "1     1    IC  laughter         2   0.231923   0.288870        NaN        NaN   \n",
       "2     2    IC  laughter         1        NaN   0.198435        NaN        NaN   \n",
       "3     2    IC  laughter         2        NaN   0.422309        NaN        NaN   \n",
       "4     3    IC  laughter         1   0.288269   0.303648   0.193177   0.187955   \n",
       "\n",
       "   IFGl_IFGr  IFGr_TPJr  IFGr_TPJl  IFGl_TPJr  IFGl_TPJl  TPJr_TPJl  \n",
       "0   0.262726   0.258718   0.285384   0.214340   0.219691        NaN  \n",
       "1   0.261279   0.239531   0.248008   0.260857   0.253972        NaN  \n",
       "2   0.229439        NaN        NaN   0.211421   0.229041        NaN  \n",
       "3   0.453068        NaN        NaN   0.217067   0.174231        NaN  \n",
       "4   0.304951   0.227554   0.234536   0.300126   0.295440   0.208585  "
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average redundant channels\n",
    "\n",
    "# Create new dataframe including the variables to keep\n",
    "\n",
    "video_data = df[['Pair', 'Group', 'Segment', 'Interval', 'IFGr_IFGr', 'IFGl_IFGl', 'TPJr_TPJr', 'TPJl_TPJl']].copy()\n",
    "\n",
    "# Define the ROI pairs and the columns to average\n",
    "roi_pairs = [\n",
    "    ('IFGl_IFGr', 'IFGr_IFGl'),\n",
    "    ('IFGr_TPJr', 'TPJr_IFGr'),\n",
    "    ('IFGr_TPJl', 'TPJl_IFGr'),\n",
    "    ('IFGl_TPJr', 'TPJr_IFGl'),\n",
    "    ('IFGl_TPJl', 'TPJl_IFGl'),\n",
    "    ('TPJr_TPJl', 'TPJl_TPJr'),\n",
    "]\n",
    "\n",
    "# Iterate through the pairs and compute the mean for each one\n",
    "for col1, col2 in roi_pairs:\n",
    "    # Compute row-wise mean for the pair of columns\n",
    "    video_data[f'{col1}'] = df[[col1, col2]].mean(axis=1)\n",
    "\n",
    "# Check the updated dataframe\n",
    "video_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 199 entries, 0 to 198\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Pair       199 non-null    int64  \n",
      " 1   Group      199 non-null    object \n",
      " 2   Segment    199 non-null    object \n",
      " 3   Interval   199 non-null    int64  \n",
      " 4   IFGr_IFGr  177 non-null    float64\n",
      " 5   IFGl_IFGl  197 non-null    float64\n",
      " 6   TPJr_TPJr  133 non-null    float64\n",
      " 7   TPJl_TPJl  135 non-null    float64\n",
      " 8   IFGl_IFGr  199 non-null    float64\n",
      " 9   IFGr_TPJr  179 non-null    float64\n",
      " 10  IFGr_TPJl  176 non-null    float64\n",
      " 11  IFGl_TPJr  195 non-null    float64\n",
      " 12  IFGl_TPJl  193 non-null    float64\n",
      " 13  TPJr_TPJl  154 non-null    float64\n",
      "dtypes: float64(10), int64(2), object(2)\n",
      "memory usage: 21.9+ KB\n"
     ]
    }
   ],
   "source": [
    "video_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Coherence during free interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IFGr_IFGr</th>\n",
       "      <th>IFGr_IFGl</th>\n",
       "      <th>IFGr_TPJr</th>\n",
       "      <th>IFGr_TPJl</th>\n",
       "      <th>IFGl_IFGr</th>\n",
       "      <th>IFGl_IFGl</th>\n",
       "      <th>IFGl_TPJr</th>\n",
       "      <th>IFGl_TPJl</th>\n",
       "      <th>TPJr_IFGr</th>\n",
       "      <th>TPJr_IFGl</th>\n",
       "      <th>TPJr_TPJr</th>\n",
       "      <th>TPJr_TPJl</th>\n",
       "      <th>TPJl_IFGr</th>\n",
       "      <th>TPJl_IFGl</th>\n",
       "      <th>TPJl_TPJr</th>\n",
       "      <th>TPJl_TPJl</th>\n",
       "      <th>Interval</th>\n",
       "      <th>Pair</th>\n",
       "      <th>Group</th>\n",
       "      <th>Segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.261954</td>\n",
       "      <td>0.229777</td>\n",
       "      <td>0.248250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.234832</td>\n",
       "      <td>0.296894</td>\n",
       "      <td>0.306257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>IC</td>\n",
       "      <td>interaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.278682</td>\n",
       "      <td>0.259312</td>\n",
       "      <td>0.236873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>IC</td>\n",
       "      <td>interaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.225737</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.254043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.281262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.276343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>IC</td>\n",
       "      <td>interaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.196668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.221411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.293187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.200420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>IC</td>\n",
       "      <td>interaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.238468</td>\n",
       "      <td>0.300067</td>\n",
       "      <td>0.213710</td>\n",
       "      <td>0.174938</td>\n",
       "      <td>0.227807</td>\n",
       "      <td>0.342319</td>\n",
       "      <td>0.262133</td>\n",
       "      <td>0.181897</td>\n",
       "      <td>0.244471</td>\n",
       "      <td>0.254158</td>\n",
       "      <td>0.190864</td>\n",
       "      <td>0.197932</td>\n",
       "      <td>0.261414</td>\n",
       "      <td>0.318280</td>\n",
       "      <td>0.255131</td>\n",
       "      <td>0.221397</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>IC</td>\n",
       "      <td>interaction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IFGr_IFGr  IFGr_IFGl  IFGr_TPJr  IFGr_TPJl  IFGl_IFGr  IFGl_IFGl  \\\n",
       "0        NaN   0.261954   0.229777   0.248250        NaN   0.234832   \n",
       "1        NaN        NaN        NaN        NaN        NaN   0.278682   \n",
       "2        NaN   0.225737        NaN        NaN        NaN   0.254043   \n",
       "3        NaN   0.196668        NaN        NaN        NaN   0.221411   \n",
       "4   0.238468   0.300067   0.213710   0.174938   0.227807   0.342319   \n",
       "\n",
       "   IFGl_TPJr  IFGl_TPJl  TPJr_IFGr  TPJr_IFGl  TPJr_TPJr  TPJr_TPJl  \\\n",
       "0   0.296894   0.306257        NaN        NaN        NaN        NaN   \n",
       "1   0.259312   0.236873        NaN        NaN        NaN        NaN   \n",
       "2        NaN        NaN        NaN   0.281262        NaN        NaN   \n",
       "3        NaN        NaN        NaN   0.293187        NaN        NaN   \n",
       "4   0.262133   0.181897   0.244471   0.254158   0.190864   0.197932   \n",
       "\n",
       "   TPJl_IFGr  TPJl_IFGl  TPJl_TPJr  TPJl_TPJl  Interval  Pair Group  \\\n",
       "0        NaN        NaN        NaN        NaN         1     1    IC   \n",
       "1        NaN        NaN        NaN        NaN         2     1    IC   \n",
       "2        NaN   0.276343        NaN        NaN         1     2    IC   \n",
       "3        NaN   0.200420        NaN        NaN         2     2    IC   \n",
       "4   0.261414   0.318280   0.255131   0.221397         1     3    IC   \n",
       "\n",
       "       Segment  \n",
       "0  interaction  \n",
       "1  interaction  \n",
       "2  interaction  \n",
       "3  interaction  \n",
       "4  interaction  "
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load free interaction data\n",
    "\n",
    "interaction_filename = coherence_folder + \"/Data_ROI_interaction_all.csv\"\n",
    "df = pd.read_csv(interaction_filename)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 194 entries, 0 to 193\n",
      "Data columns (total 20 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   IFGr_IFGr  137 non-null    float64\n",
      " 1   IFGr_IFGl  156 non-null    float64\n",
      " 2   IFGr_TPJr  125 non-null    float64\n",
      " 3   IFGr_TPJl  134 non-null    float64\n",
      " 4   IFGl_IFGr  147 non-null    float64\n",
      " 5   IFGl_IFGl  171 non-null    float64\n",
      " 6   IFGl_TPJr  137 non-null    float64\n",
      " 7   IFGl_TPJl  150 non-null    float64\n",
      " 8   TPJr_IFGr  131 non-null    float64\n",
      " 9   TPJr_IFGl  146 non-null    float64\n",
      " 10  TPJr_TPJr  114 non-null    float64\n",
      " 11  TPJr_TPJl  126 non-null    float64\n",
      " 12  TPJl_IFGr  126 non-null    float64\n",
      " 13  TPJl_IFGl  140 non-null    float64\n",
      " 14  TPJl_TPJr  105 non-null    float64\n",
      " 15  TPJl_TPJl  121 non-null    float64\n",
      " 16  Interval   194 non-null    int64  \n",
      " 17  Pair       194 non-null    int64  \n",
      " 18  Group      194 non-null    object \n",
      " 19  Segment    194 non-null    object \n",
      "dtypes: float64(16), int64(2), object(2)\n",
      "memory usage: 30.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pair</th>\n",
       "      <th>Group</th>\n",
       "      <th>Segment</th>\n",
       "      <th>Interval</th>\n",
       "      <th>IFGr_IFGr</th>\n",
       "      <th>IFGl_IFGl</th>\n",
       "      <th>TPJr_TPJr</th>\n",
       "      <th>TPJl_TPJl</th>\n",
       "      <th>IFGl_IFGr</th>\n",
       "      <th>IFGr_TPJr</th>\n",
       "      <th>IFGr_TPJl</th>\n",
       "      <th>IFGl_TPJr</th>\n",
       "      <th>IFGl_TPJl</th>\n",
       "      <th>TPJr_TPJl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>IC</td>\n",
       "      <td>interaction</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.234832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.261954</td>\n",
       "      <td>0.229777</td>\n",
       "      <td>0.248250</td>\n",
       "      <td>0.296894</td>\n",
       "      <td>0.306257</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>IC</td>\n",
       "      <td>interaction</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.278682</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.259312</td>\n",
       "      <td>0.236873</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>IC</td>\n",
       "      <td>interaction</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.254043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.225737</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.281262</td>\n",
       "      <td>0.276343</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>IC</td>\n",
       "      <td>interaction</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.221411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.196668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.293187</td>\n",
       "      <td>0.200420</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>IC</td>\n",
       "      <td>interaction</td>\n",
       "      <td>3</td>\n",
       "      <td>0.238468</td>\n",
       "      <td>0.342319</td>\n",
       "      <td>0.190864</td>\n",
       "      <td>0.221397</td>\n",
       "      <td>0.263937</td>\n",
       "      <td>0.229090</td>\n",
       "      <td>0.218176</td>\n",
       "      <td>0.258146</td>\n",
       "      <td>0.250088</td>\n",
       "      <td>0.226531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pair Group      Segment  Interval  IFGr_IFGr  IFGl_IFGl  TPJr_TPJr  \\\n",
       "0     1    IC  interaction         3        NaN   0.234832        NaN   \n",
       "1     1    IC  interaction         4        NaN   0.278682        NaN   \n",
       "2     2    IC  interaction         3        NaN   0.254043        NaN   \n",
       "3     2    IC  interaction         4        NaN   0.221411        NaN   \n",
       "4     3    IC  interaction         3   0.238468   0.342319   0.190864   \n",
       "\n",
       "   TPJl_TPJl  IFGl_IFGr  IFGr_TPJr  IFGr_TPJl  IFGl_TPJr  IFGl_TPJl  TPJr_TPJl  \n",
       "0        NaN   0.261954   0.229777   0.248250   0.296894   0.306257        NaN  \n",
       "1        NaN        NaN        NaN        NaN   0.259312   0.236873        NaN  \n",
       "2        NaN   0.225737        NaN        NaN   0.281262   0.276343        NaN  \n",
       "3        NaN   0.196668        NaN        NaN   0.293187   0.200420        NaN  \n",
       "4   0.221397   0.263937   0.229090   0.218176   0.258146   0.250088   0.226531  "
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average redundant channels\n",
    "\n",
    "# Create new dataframe including the variables to keep\n",
    "\n",
    "interaction_data = df[['Pair', 'Group', 'Segment', 'Interval', 'IFGr_IFGr', 'IFGl_IFGl', 'TPJr_TPJr', 'TPJl_TPJl']].copy()\n",
    "\n",
    "# Define the ROI pairs and the columns to average\n",
    "roi_pairs = [\n",
    "    ('IFGl_IFGr', 'IFGr_IFGl'),\n",
    "    ('IFGr_TPJr', 'TPJr_IFGr'),\n",
    "    ('IFGr_TPJl', 'TPJl_IFGr'),\n",
    "    ('IFGl_TPJr', 'TPJr_IFGl'),\n",
    "    ('IFGl_TPJl', 'TPJl_IFGl'),\n",
    "    ('TPJr_TPJl', 'TPJl_TPJr'),\n",
    "]\n",
    "\n",
    "# Iterate through the pairs and compute the mean for each one\n",
    "for col1, col2 in roi_pairs:\n",
    "    # Compute row-wise mean for the pair of columns\n",
    "    interaction_data[f'{col1}'] = df[[col1, col2]].mean(axis=1)\n",
    "\n",
    "\n",
    "# Change labelling of interval: instead of 1 and 2, 3 and 4\n",
    "interaction_data['Interval'] = interaction_data['Interval']+ 2\n",
    "\n",
    "# Check the updated dataframe\n",
    "interaction_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 194 entries, 0 to 193\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Pair       194 non-null    int64  \n",
      " 1   Group      194 non-null    object \n",
      " 2   Segment    194 non-null    object \n",
      " 3   Interval   194 non-null    int64  \n",
      " 4   IFGr_IFGr  137 non-null    float64\n",
      " 5   IFGl_IFGl  171 non-null    float64\n",
      " 6   TPJr_TPJr  114 non-null    float64\n",
      " 7   TPJl_TPJl  121 non-null    float64\n",
      " 8   IFGl_IFGr  178 non-null    float64\n",
      " 9   IFGr_TPJr  162 non-null    float64\n",
      " 10  IFGr_TPJl  163 non-null    float64\n",
      " 11  IFGl_TPJr  184 non-null    float64\n",
      " 12  IFGl_TPJl  185 non-null    float64\n",
      " 13  TPJr_TPJl  137 non-null    float64\n",
      "dtypes: float64(10), int64(2), object(2)\n",
      "memory usage: 21.3+ KB\n"
     ]
    }
   ],
   "source": [
    "interaction_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3 Append coherence data in one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append the two dataframes\n",
    "\n",
    "coherence_data = pd.concat([video_data, interaction_data], ignore_index=True)\n",
    "\n",
    "coherence_data.head()\n",
    "\n",
    "# save for later use\n",
    "filename_data = data_path + \"/coherence_data.csv\"\n",
    "coherence_data.to_csv(filename_data, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 393 entries, 0 to 392\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Pair       393 non-null    int64  \n",
      " 1   Group      393 non-null    object \n",
      " 2   Segment    393 non-null    object \n",
      " 3   Interval   393 non-null    int64  \n",
      " 4   IFGr_IFGr  314 non-null    float64\n",
      " 5   IFGl_IFGl  368 non-null    float64\n",
      " 6   TPJr_TPJr  247 non-null    float64\n",
      " 7   TPJl_TPJl  256 non-null    float64\n",
      " 8   IFGl_IFGr  377 non-null    float64\n",
      " 9   IFGr_TPJr  341 non-null    float64\n",
      " 10  IFGr_TPJl  339 non-null    float64\n",
      " 11  IFGl_TPJr  379 non-null    float64\n",
      " 12  IFGl_TPJl  378 non-null    float64\n",
      " 13  TPJr_TPJl  291 non-null    float64\n",
      "dtypes: float64(10), int64(2), object(2)\n",
      "memory usage: 43.1+ KB\n"
     ]
    }
   ],
   "source": [
    "coherence_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pair</th>\n",
       "      <th>Interval</th>\n",
       "      <th>IFGr_IFGr</th>\n",
       "      <th>IFGl_IFGl</th>\n",
       "      <th>TPJr_TPJr</th>\n",
       "      <th>TPJl_TPJl</th>\n",
       "      <th>IFGl_IFGr</th>\n",
       "      <th>IFGr_TPJr</th>\n",
       "      <th>IFGr_TPJl</th>\n",
       "      <th>IFGl_TPJr</th>\n",
       "      <th>IFGl_TPJl</th>\n",
       "      <th>TPJr_TPJl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>393.000000</td>\n",
       "      <td>393.000000</td>\n",
       "      <td>314.000000</td>\n",
       "      <td>368.000000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>341.000000</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>379.000000</td>\n",
       "      <td>378.000000</td>\n",
       "      <td>291.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.188295</td>\n",
       "      <td>2.486005</td>\n",
       "      <td>0.278476</td>\n",
       "      <td>0.275465</td>\n",
       "      <td>0.280907</td>\n",
       "      <td>0.276633</td>\n",
       "      <td>0.278824</td>\n",
       "      <td>0.274032</td>\n",
       "      <td>0.275987</td>\n",
       "      <td>0.271864</td>\n",
       "      <td>0.272334</td>\n",
       "      <td>0.277691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.427896</td>\n",
       "      <td>1.120510</td>\n",
       "      <td>0.062932</td>\n",
       "      <td>0.060387</td>\n",
       "      <td>0.062117</td>\n",
       "      <td>0.060263</td>\n",
       "      <td>0.050774</td>\n",
       "      <td>0.049678</td>\n",
       "      <td>0.050294</td>\n",
       "      <td>0.051936</td>\n",
       "      <td>0.049237</td>\n",
       "      <td>0.049425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.131923</td>\n",
       "      <td>0.154268</td>\n",
       "      <td>0.147143</td>\n",
       "      <td>0.139612</td>\n",
       "      <td>0.156761</td>\n",
       "      <td>0.131825</td>\n",
       "      <td>0.162377</td>\n",
       "      <td>0.152551</td>\n",
       "      <td>0.170665</td>\n",
       "      <td>0.162374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.233011</td>\n",
       "      <td>0.231536</td>\n",
       "      <td>0.234332</td>\n",
       "      <td>0.228557</td>\n",
       "      <td>0.241112</td>\n",
       "      <td>0.242223</td>\n",
       "      <td>0.239869</td>\n",
       "      <td>0.238155</td>\n",
       "      <td>0.236484</td>\n",
       "      <td>0.243337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.273019</td>\n",
       "      <td>0.266415</td>\n",
       "      <td>0.277720</td>\n",
       "      <td>0.271110</td>\n",
       "      <td>0.273881</td>\n",
       "      <td>0.268057</td>\n",
       "      <td>0.273256</td>\n",
       "      <td>0.268829</td>\n",
       "      <td>0.268162</td>\n",
       "      <td>0.270801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.318583</td>\n",
       "      <td>0.314437</td>\n",
       "      <td>0.323039</td>\n",
       "      <td>0.313877</td>\n",
       "      <td>0.311751</td>\n",
       "      <td>0.304163</td>\n",
       "      <td>0.304178</td>\n",
       "      <td>0.300299</td>\n",
       "      <td>0.301968</td>\n",
       "      <td>0.309163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.504713</td>\n",
       "      <td>0.468392</td>\n",
       "      <td>0.452858</td>\n",
       "      <td>0.458713</td>\n",
       "      <td>0.453068</td>\n",
       "      <td>0.479757</td>\n",
       "      <td>0.459239</td>\n",
       "      <td>0.542336</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.428475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pair    Interval   IFGr_IFGr   IFGl_IFGl   TPJr_TPJr   TPJl_TPJl  \\\n",
       "count  393.000000  393.000000  314.000000  368.000000  247.000000  256.000000   \n",
       "mean    13.188295    2.486005    0.278476    0.275465    0.280907    0.276633   \n",
       "std      7.427896    1.120510    0.062932    0.060387    0.062117    0.060263   \n",
       "min      1.000000    1.000000    0.131923    0.154268    0.147143    0.139612   \n",
       "25%      7.000000    1.000000    0.233011    0.231536    0.234332    0.228557   \n",
       "50%     13.000000    2.000000    0.273019    0.266415    0.277720    0.271110   \n",
       "75%     20.000000    3.000000    0.318583    0.314437    0.323039    0.313877   \n",
       "max     26.000000    4.000000    0.504713    0.468392    0.452858    0.458713   \n",
       "\n",
       "        IFGl_IFGr   IFGr_TPJr   IFGr_TPJl   IFGl_TPJr   IFGl_TPJl   TPJr_TPJl  \n",
       "count  377.000000  341.000000  339.000000  379.000000  378.000000  291.000000  \n",
       "mean     0.278824    0.274032    0.275987    0.271864    0.272334    0.277691  \n",
       "std      0.050774    0.049678    0.050294    0.051936    0.049237    0.049425  \n",
       "min      0.156761    0.131825    0.162377    0.152551    0.170665    0.162374  \n",
       "25%      0.241112    0.242223    0.239869    0.238155    0.236484    0.243337  \n",
       "50%      0.273881    0.268057    0.273256    0.268829    0.268162    0.270801  \n",
       "75%      0.311751    0.304163    0.304178    0.300299    0.301968    0.309163  \n",
       "max      0.453068    0.479757    0.459239    0.542336    0.446530    0.428475  "
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Questionnaire data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Participant Information', 'General information_v1', 'PANAS_v1', 'Handiness', 'BFI-10', 'Videos', 'PANAS_v2', 'Free Time Studie', 'Questions_v2', 'IOS']\n"
     ]
    }
   ],
   "source": [
    "# load questionnaire data\n",
    "\n",
    "questionnaire_filename = data_path + \"/Excel_Auswertung_2(Franzi).xlsx\"\n",
    "\n",
    "sheet_names = pd.ExcelFile(questionnaire_filename).sheet_names\n",
    "print(sheet_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 Participant Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\env_wifiautogluon\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Group</th>\n",
       "      <th>Pair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>21.0</td>\n",
       "      <td>f</td>\n",
       "      <td>IL</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>18.0</td>\n",
       "      <td>f</td>\n",
       "      <td>IL</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>21.0</td>\n",
       "      <td>f</td>\n",
       "      <td>IL</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>18.0</td>\n",
       "      <td>f</td>\n",
       "      <td>IL</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>19.0</td>\n",
       "      <td>f</td>\n",
       "      <td>IL</td>\n",
       "      <td>03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant   Age Gender Group Pair\n",
       "0           A  21.0      f    IL   01\n",
       "1           B  18.0      f    IL   01\n",
       "2           A  21.0      f    IL   02\n",
       "3           B  18.0      f    IL   02\n",
       "4           A  19.0      f    IL   03"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheet_name = 'Participant Information'\n",
    "\n",
    "# Load the specified sheet into a DataFrame\n",
    "df = pd.read_excel(questionnaire_filename, sheet_name=sheet_name)\n",
    "\n",
    "# get only relevant rows and columns\n",
    "part_info = df.iloc[2:, 0:3]\n",
    "\n",
    "# Rename the columns (headers)\n",
    "part_info.columns = ['Participant', 'Age', 'Gender']\n",
    "\n",
    "# convert Age to numeric\n",
    "part_info['Age'] = pd.to_numeric(part_info['Age'], errors='coerce')\n",
    "\n",
    "# convert Gender to categorical\n",
    "part_info['Gender'] = part_info['Gender'].astype('category')\n",
    "\n",
    "# Drop rows where 'Column 1' contains the letter 'P'\n",
    "part_info = part_info[~part_info['Participant'].str.contains('P', case=False, na=False)]\n",
    "\n",
    "# Drop rows where any column contains NaN\n",
    "part_info = part_info.dropna(how='any')\n",
    "\n",
    "# split group, pair number and participant label into three different columns\n",
    "part_info[['Group', 'Pair', 'Participant']] = part_info['Participant'].str.extract(r'([A-Za-z]+)\\s*(\\d+)\\s*([A-Za-z])')\n",
    "\n",
    "# Reset the index\n",
    "part_info.reset_index(drop=True, inplace=True)\n",
    "\n",
    "part_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 Liking_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant</th>\n",
       "      <th>Comfort_Pre</th>\n",
       "      <th>Likeable_Pre</th>\n",
       "      <th>More_Time_Pre</th>\n",
       "      <th>Group</th>\n",
       "      <th>Pair</th>\n",
       "      <th>Mean_liking_Pre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IL</td>\n",
       "      <td>01</td>\n",
       "      <td>3.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>IL</td>\n",
       "      <td>01</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>IL</td>\n",
       "      <td>02</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>IL</td>\n",
       "      <td>02</td>\n",
       "      <td>6.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>IL</td>\n",
       "      <td>03</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant  Comfort_Pre  Likeable_Pre  More_Time_Pre Group Pair  \\\n",
       "0           A          6.0           5.0            0.0    IL   01   \n",
       "1           B          7.0           7.0            7.0    IL   01   \n",
       "2           A          7.0           8.0            6.0    IL   02   \n",
       "3           B          6.0           7.0            6.0    IL   02   \n",
       "4           A          8.0           8.0            8.0    IL   03   \n",
       "\n",
       "   Mean_liking_Pre  \n",
       "0         3.666667  \n",
       "1         7.000000  \n",
       "2         7.000000  \n",
       "3         6.333333  \n",
       "4         8.000000  "
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheet_name = 'General information_v1'\n",
    "\n",
    "# Load the specified sheet into a DataFrame\n",
    "df = pd.read_excel(questionnaire_filename, sheet_name=sheet_name)\n",
    "\n",
    "# get only relevant rows and columns\n",
    "df = df.iloc[4:, ]\n",
    "\n",
    "# Set the first row as header and reset the dataframe\n",
    "df.columns = df.iloc[0]  # Set first row as column headers\n",
    "df = df.drop(4)  # Drop the first row, as it is now the header\n",
    "\n",
    "# Rename the columns (headers)\n",
    "df.columns = ['Participant', 'Comfort_Pre', 'Likeable_Pre', 'More_Time_Pre']\n",
    "\n",
    "# convert scores to numeric\n",
    "df[['Comfort_Pre', 'Likeable_Pre', 'More_Time_Pre']] = df[['Comfort_Pre', 'Likeable_Pre', 'More_Time_Pre']].apply(pd.to_numeric, errors = 'coerce')\n",
    "\n",
    "# Drop rows where 'Column 1' contains the letter 'P'\n",
    "df = df[~df['Participant'].str.contains('P', case=False, na=False)]\n",
    "\n",
    "# Drop rows where any column contains NaN\n",
    "df = df.dropna(how='any')\n",
    "\n",
    "# Reset the index (optional)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# split group, pair number and participant label into three different columns\n",
    "df[['Group', 'Pair', 'Participant']] = df['Participant'].str.extract(r'([A-Za-z]+)\\s*(\\d+)\\s*([A-Za-z])')\n",
    "\n",
    "# create mean liking\n",
    "df['Mean_liking_Pre'] = df[['Comfort_Pre', 'Likeable_Pre', 'More_Time_Pre']].mean(axis = 1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Group</th>\n",
       "      <th>Pair</th>\n",
       "      <th>Mean_liking_Pre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>19.0</td>\n",
       "      <td>f</td>\n",
       "      <td>IC</td>\n",
       "      <td>01</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>21.0</td>\n",
       "      <td>f</td>\n",
       "      <td>IC</td>\n",
       "      <td>02</td>\n",
       "      <td>7.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>22.0</td>\n",
       "      <td>f</td>\n",
       "      <td>IC</td>\n",
       "      <td>03</td>\n",
       "      <td>6.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>21.0</td>\n",
       "      <td>m</td>\n",
       "      <td>IC</td>\n",
       "      <td>04</td>\n",
       "      <td>5.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>22.0</td>\n",
       "      <td>f</td>\n",
       "      <td>IC</td>\n",
       "      <td>05</td>\n",
       "      <td>6.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant   Age Gender Group Pair  Mean_liking_Pre\n",
       "0           A  19.0      f    IC   01         8.000000\n",
       "1           A  21.0      f    IC   02         7.333333\n",
       "2           A  22.0      f    IC   03         6.666667\n",
       "3           A  21.0      m    IC   04         5.333333\n",
       "4           A  22.0      f    IC   05         6.666667"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop unncecessary variables\n",
    "df = df.drop(['Comfort_Pre', 'Likeable_Pre', 'More_Time_Pre'], axis = 1)\n",
    "\n",
    "# merge the two dataframes\n",
    "\n",
    "part_info = pd.merge(part_info, df, on=[\"Participant\", \"Group\", \"Pair\"], how=\"outer\")\n",
    "\n",
    "part_info.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 204 entries, 0 to 203\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype   \n",
      "---  ------           --------------  -----   \n",
      " 0   Participant      204 non-null    object  \n",
      " 1   Age              204 non-null    float64 \n",
      " 2   Gender           204 non-null    category\n",
      " 3   Group            204 non-null    object  \n",
      " 4   Pair             204 non-null    object  \n",
      " 5   Mean_liking_Pre  204 non-null    float64 \n",
      "dtypes: category(1), float64(2), object(3)\n",
      "memory usage: 8.4+ KB\n"
     ]
    }
   ],
   "source": [
    "part_info.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.3 Liking_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant</th>\n",
       "      <th>Comfort_Post</th>\n",
       "      <th>Likeable_Post</th>\n",
       "      <th>More_Time_Post</th>\n",
       "      <th>Group</th>\n",
       "      <th>Pair</th>\n",
       "      <th>Mean_liking_Post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IL</td>\n",
       "      <td>01</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>IL</td>\n",
       "      <td>01</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>IL</td>\n",
       "      <td>02</td>\n",
       "      <td>6.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>IL</td>\n",
       "      <td>02</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>IL</td>\n",
       "      <td>03</td>\n",
       "      <td>7.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant  Comfort_Post  Likeable_Post  More_Time_Post Group Pair  \\\n",
       "0           A           6.0            6.0             0.0    IL   01   \n",
       "1           B           7.0            7.0             7.0    IL   01   \n",
       "2           A           7.0            8.0             4.0    IL   02   \n",
       "3           B           7.0            7.0             7.0    IL   02   \n",
       "4           A           8.0            8.0             6.0    IL   03   \n",
       "\n",
       "   Mean_liking_Post  \n",
       "0          4.000000  \n",
       "1          7.000000  \n",
       "2          6.333333  \n",
       "3          7.000000  \n",
       "4          7.333333  "
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheet_name = 'Questions_v2'\n",
    "\n",
    "# Load the specified sheet into a DataFrame\n",
    "df = pd.read_excel(questionnaire_filename, sheet_name=sheet_name)\n",
    "\n",
    "# get only relevant rows and columns\n",
    "df = df.iloc[3:, ]\n",
    "\n",
    "# Set the first row as header and reset the dataframe\n",
    "df.columns = df.iloc[0]  # Set first row as column headers\n",
    "df = df.drop(3)  # Drop the first row, as it is now the header\n",
    "\n",
    "# Rename the columns (headers)\n",
    "df.columns = ['Participant', 'Comfort_Post', 'Likeable_Post', 'More_Time_Post']\n",
    "\n",
    "# convert scores to numeric\n",
    "df[['Comfort_Post', 'Likeable_Post', 'More_Time_Post']] = df[['Comfort_Post', 'Likeable_Post', 'More_Time_Post']].apply(pd.to_numeric, errors = 'coerce')\n",
    "\n",
    "# Drop rows where 'Column 1' contains the letter 'P'\n",
    "df = df[~df['Participant'].str.contains('P', case=False, na=False)]\n",
    "\n",
    "# Drop rows where any column contains NaN\n",
    "df = df.dropna(how='any')\n",
    "\n",
    "# Reset the index (optional)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# split group, pair number and participant label into three different columns\n",
    "df[['Group', 'Pair', 'Participant']] = df['Participant'].str.extract(r'([A-Za-z]+)\\s*(\\d+)\\s*([A-Za-z])')\n",
    "\n",
    "# create mean liking\n",
    "df['Mean_liking_Post'] = df[['Comfort_Post', 'Likeable_Post', 'More_Time_Post']].mean(axis = 1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Group</th>\n",
       "      <th>Pair</th>\n",
       "      <th>Mean_liking_Pre</th>\n",
       "      <th>Mean_liking_Post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>19.0</td>\n",
       "      <td>f</td>\n",
       "      <td>IC</td>\n",
       "      <td>1</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>21.0</td>\n",
       "      <td>f</td>\n",
       "      <td>IC</td>\n",
       "      <td>2</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>22.0</td>\n",
       "      <td>f</td>\n",
       "      <td>IC</td>\n",
       "      <td>3</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>21.0</td>\n",
       "      <td>m</td>\n",
       "      <td>IC</td>\n",
       "      <td>4</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>4.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>22.0</td>\n",
       "      <td>f</td>\n",
       "      <td>IC</td>\n",
       "      <td>5</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>6.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant   Age Gender Group  Pair  Mean_liking_Pre  Mean_liking_Post\n",
       "0           A  19.0      f    IC     1         8.000000          8.000000\n",
       "1           A  21.0      f    IC     2         7.333333          8.000000\n",
       "2           A  22.0      f    IC     3         6.666667          7.000000\n",
       "3           A  21.0      m    IC     4         5.333333          4.333333\n",
       "4           A  22.0      f    IC     5         6.666667          6.666667"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop unncecessary variables\n",
    "df = df.drop(['Comfort_Post', 'Likeable_Post', 'More_Time_Post'], axis = 1)\n",
    "\n",
    "# merge the two dataframes\n",
    "\n",
    "part_info = pd.merge(part_info, df, on=[\"Participant\", \"Group\", \"Pair\"], how=\"outer\")\n",
    "\n",
    "# convert Pair to numeric\n",
    "part_info['Pair'] = pd.to_numeric(part_info['Pair'])\n",
    "\n",
    "part_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 204 entries, 0 to 203\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype   \n",
      "---  ------            --------------  -----   \n",
      " 0   Participant       204 non-null    object  \n",
      " 1   Age               204 non-null    float64 \n",
      " 2   Gender            204 non-null    category\n",
      " 3   Group             204 non-null    object  \n",
      " 4   Pair              204 non-null    int64   \n",
      " 5   Mean_liking_Pre   204 non-null    float64 \n",
      " 6   Mean_liking_Post  204 non-null    float64 \n",
      "dtypes: category(1), float64(3), int64(1), object(2)\n",
      "memory usage: 10.0+ KB\n"
     ]
    }
   ],
   "source": [
    "part_info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data for later use\n",
    "filename_data = data_path + \"/questionnaire_LT_data.csv\"\n",
    "df.to_csv(filename_data, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Merge all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coherence Pair values: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 19 20 21 22 23 24 25\n",
      " 18 26]\n",
      "coherence_data Group values: ['IC' 'IL' 'NIC' 'NIL']\n",
      "part_info Pair values: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26]\n",
      "part_info Group values: ['IC' 'IL' 'NIC' 'NIL']\n"
     ]
    }
   ],
   "source": [
    "print(\"coherence Pair values:\", coherence_data['Pair'].unique())\n",
    "print(\"coherence_data Group values:\", coherence_data['Group'].unique())\n",
    "print(\"part_info Pair values:\", part_info['Pair'].unique())\n",
    "print(\"part_info Group values:\", part_info['Group'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Group</th>\n",
       "      <th>Pair</th>\n",
       "      <th>Mean_liking_Pre</th>\n",
       "      <th>Mean_liking_Post</th>\n",
       "      <th>Segment</th>\n",
       "      <th>Interval</th>\n",
       "      <th>IFGr_IFGr</th>\n",
       "      <th>IFGl_IFGl</th>\n",
       "      <th>TPJr_TPJr</th>\n",
       "      <th>TPJl_TPJl</th>\n",
       "      <th>IFGl_IFGr</th>\n",
       "      <th>IFGr_TPJr</th>\n",
       "      <th>IFGr_TPJl</th>\n",
       "      <th>IFGl_TPJr</th>\n",
       "      <th>IFGl_TPJl</th>\n",
       "      <th>TPJr_TPJl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>19.0</td>\n",
       "      <td>f</td>\n",
       "      <td>IC</td>\n",
       "      <td>1</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>laughter</td>\n",
       "      <td>1</td>\n",
       "      <td>0.253717</td>\n",
       "      <td>0.215108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.262726</td>\n",
       "      <td>0.258718</td>\n",
       "      <td>0.285384</td>\n",
       "      <td>0.214340</td>\n",
       "      <td>0.219691</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>19.0</td>\n",
       "      <td>f</td>\n",
       "      <td>IC</td>\n",
       "      <td>1</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>laughter</td>\n",
       "      <td>2</td>\n",
       "      <td>0.231923</td>\n",
       "      <td>0.288870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.261279</td>\n",
       "      <td>0.239531</td>\n",
       "      <td>0.248008</td>\n",
       "      <td>0.260857</td>\n",
       "      <td>0.253972</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>19.0</td>\n",
       "      <td>f</td>\n",
       "      <td>IC</td>\n",
       "      <td>1</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>interaction</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.234832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.261954</td>\n",
       "      <td>0.229777</td>\n",
       "      <td>0.248250</td>\n",
       "      <td>0.296894</td>\n",
       "      <td>0.306257</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>19.0</td>\n",
       "      <td>f</td>\n",
       "      <td>IC</td>\n",
       "      <td>1</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>interaction</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.278682</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.259312</td>\n",
       "      <td>0.236873</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>21.0</td>\n",
       "      <td>f</td>\n",
       "      <td>IC</td>\n",
       "      <td>2</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>8.0</td>\n",
       "      <td>laughter</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.198435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.229439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.211421</td>\n",
       "      <td>0.229041</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant   Age Gender Group  Pair  Mean_liking_Pre  Mean_liking_Post  \\\n",
       "0           A  19.0      f    IC     1         8.000000               8.0   \n",
       "1           A  19.0      f    IC     1         8.000000               8.0   \n",
       "2           A  19.0      f    IC     1         8.000000               8.0   \n",
       "3           A  19.0      f    IC     1         8.000000               8.0   \n",
       "4           A  21.0      f    IC     2         7.333333               8.0   \n",
       "\n",
       "       Segment  Interval  IFGr_IFGr  IFGl_IFGl  TPJr_TPJr  TPJl_TPJl  \\\n",
       "0     laughter         1   0.253717   0.215108        NaN        NaN   \n",
       "1     laughter         2   0.231923   0.288870        NaN        NaN   \n",
       "2  interaction         3        NaN   0.234832        NaN        NaN   \n",
       "3  interaction         4        NaN   0.278682        NaN        NaN   \n",
       "4     laughter         1        NaN   0.198435        NaN        NaN   \n",
       "\n",
       "   IFGl_IFGr  IFGr_TPJr  IFGr_TPJl  IFGl_TPJr  IFGl_TPJl  TPJr_TPJl  \n",
       "0   0.262726   0.258718   0.285384   0.214340   0.219691        NaN  \n",
       "1   0.261279   0.239531   0.248008   0.260857   0.253972        NaN  \n",
       "2   0.261954   0.229777   0.248250   0.296894   0.306257        NaN  \n",
       "3        NaN        NaN        NaN   0.259312   0.236873        NaN  \n",
       "4   0.229439        NaN        NaN   0.211421   0.229041        NaN  "
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the two dataframes\n",
    "\n",
    "all_data = pd.merge(part_info, coherence_data, on=[\"Group\", \"Pair\"], how=\"inner\")\n",
    "\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 786 entries, 0 to 785\n",
      "Data columns (total 19 columns):\n",
      " #   Column            Non-Null Count  Dtype   \n",
      "---  ------            --------------  -----   \n",
      " 0   Participant       786 non-null    object  \n",
      " 1   Age               786 non-null    float64 \n",
      " 2   Gender            786 non-null    category\n",
      " 3   Group             786 non-null    object  \n",
      " 4   Pair              786 non-null    int64   \n",
      " 5   Mean_liking_Pre   786 non-null    float64 \n",
      " 6   Mean_liking_Post  786 non-null    float64 \n",
      " 7   Segment           786 non-null    object  \n",
      " 8   Interval          786 non-null    int64   \n",
      " 9   IFGr_IFGr         628 non-null    float64 \n",
      " 10  IFGl_IFGl         736 non-null    float64 \n",
      " 11  TPJr_TPJr         494 non-null    float64 \n",
      " 12  TPJl_TPJl         512 non-null    float64 \n",
      " 13  IFGl_IFGr         754 non-null    float64 \n",
      " 14  IFGr_TPJr         682 non-null    float64 \n",
      " 15  IFGr_TPJl         678 non-null    float64 \n",
      " 16  IFGl_TPJr         758 non-null    float64 \n",
      " 17  IFGl_TPJl         756 non-null    float64 \n",
      " 18  TPJr_TPJl         582 non-null    float64 \n",
      "dtypes: category(1), float64(13), int64(2), object(3)\n",
      "memory usage: 111.6+ KB\n"
     ]
    }
   ],
   "source": [
    "all_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Clean data (real data only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Mean_liking_Pre</th>\n",
       "      <th>Mean_liking_Post</th>\n",
       "      <th>IFGr_IFGr</th>\n",
       "      <th>IFGl_IFGl</th>\n",
       "      <th>TPJr_TPJr</th>\n",
       "      <th>TPJl_TPJl</th>\n",
       "      <th>IFGl_IFGr</th>\n",
       "      <th>IFGr_TPJr</th>\n",
       "      <th>IFGr_TPJl</th>\n",
       "      <th>IFGl_TPJr</th>\n",
       "      <th>IFGl_TPJl</th>\n",
       "      <th>TPJr_TPJl</th>\n",
       "      <th>laughter_group</th>\n",
       "      <th>interaction_group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combined</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NIL24_B_4</th>\n",
       "      <td>23.0</td>\n",
       "      <td>f</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.329731</td>\n",
       "      <td>0.264475</td>\n",
       "      <td>0.314380</td>\n",
       "      <td>0.233995</td>\n",
       "      <td>0.322295</td>\n",
       "      <td>0.231246</td>\n",
       "      <td>0.226679</td>\n",
       "      <td>0.266490</td>\n",
       "      <td>0.258251</td>\n",
       "      <td>0.247747</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IC10_A_4</th>\n",
       "      <td>22.0</td>\n",
       "      <td>f</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>0.203247</td>\n",
       "      <td>0.237688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.216901</td>\n",
       "      <td>0.247509</td>\n",
       "      <td>0.227032</td>\n",
       "      <td>0.305190</td>\n",
       "      <td>0.214944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIC12_A_3</th>\n",
       "      <td>19.0</td>\n",
       "      <td>f</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.254039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.330648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.269665</td>\n",
       "      <td>0.357894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIC1_A_3</th>\n",
       "      <td>19.0</td>\n",
       "      <td>f</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.274304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.404315</td>\n",
       "      <td>0.267253</td>\n",
       "      <td>0.272220</td>\n",
       "      <td>0.282518</td>\n",
       "      <td>0.223234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIC18_A_3</th>\n",
       "      <td>24.0</td>\n",
       "      <td>m</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.154268</td>\n",
       "      <td>0.243228</td>\n",
       "      <td>0.376470</td>\n",
       "      <td>0.205237</td>\n",
       "      <td>0.175599</td>\n",
       "      <td>0.190539</td>\n",
       "      <td>0.294580</td>\n",
       "      <td>0.331686</td>\n",
       "      <td>0.264672</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Age Gender  Mean_liking_Pre  Mean_liking_Post  IFGr_IFGr  \\\n",
       "combined                                                               \n",
       "NIL24_B_4  23.0      f         6.000000          5.666667   0.329731   \n",
       "IC10_A_4   22.0      f         6.000000          6.666667   0.203247   \n",
       "NIC12_A_3  19.0      f         5.666667          6.666667        NaN   \n",
       "NIC1_A_3   19.0      f         7.666667          8.000000        NaN   \n",
       "NIC18_A_3  24.0      m         5.333333          6.000000        NaN   \n",
       "\n",
       "           IFGl_IFGl  TPJr_TPJr  TPJl_TPJl  IFGl_IFGr  IFGr_TPJr  IFGr_TPJl  \\\n",
       "combined                                                                      \n",
       "NIL24_B_4   0.264475   0.314380   0.233995   0.322295   0.231246   0.226679   \n",
       "IC10_A_4    0.237688        NaN        NaN   0.216901   0.247509   0.227032   \n",
       "NIC12_A_3   0.254039        NaN        NaN   0.330648        NaN        NaN   \n",
       "NIC1_A_3    0.274304        NaN        NaN   0.404315   0.267253   0.272220   \n",
       "NIC18_A_3   0.154268   0.243228   0.376470   0.205237   0.175599   0.190539   \n",
       "\n",
       "           IFGl_TPJr  IFGl_TPJl  TPJr_TPJl  laughter_group  interaction_group  \n",
       "combined                                                                       \n",
       "NIL24_B_4   0.266490   0.258251   0.247747            True              False  \n",
       "IC10_A_4    0.305190   0.214944        NaN           False               True  \n",
       "NIC12_A_3   0.269665   0.357894        NaN           False              False  \n",
       "NIC1_A_3    0.282518   0.223234        NaN           False              False  \n",
       "NIC18_A_3   0.294580   0.331686   0.264672           False              False  "
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set pair, participant and segment as indexes\n",
    "\n",
    "#all_data.set_index([\"Pair\", \"Participant\", \"Segment\"], inplace=True)\n",
    "all_data['combined'] = all_data['Group'] + all_data['Pair'].astype(str) + '_' + all_data['Participant'] + '_' + all_data['Interval'].astype(str)\n",
    "\n",
    "all_data.set_index('combined', inplace=True)\n",
    "\n",
    "# divide group into two variables: laughter_group (0,1) and interaction_group(0,1)\n",
    "all_data['laughter_group'] = (all_data['Group'].str.contains('L', case=False, na=False))\n",
    "all_data['interaction_group'] = (~all_data['Group'].str.contains('N', case=False, na=False))\n",
    "\n",
    "# drop unnecessary variables\n",
    "all_data = all_data.drop(['Participant', 'Pair', 'Segment', 'Group', 'Interval'], axis = 1)\n",
    "\n",
    "\n",
    "# Display the updated DataFrame with multi-index\n",
    "all_data.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 786 entries, IC1_A_1 to NIL9_B_4\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count  Dtype   \n",
      "---  ------             --------------  -----   \n",
      " 0   Age                786 non-null    float64 \n",
      " 1   Gender             786 non-null    category\n",
      " 2   Mean_liking_Pre    786 non-null    float64 \n",
      " 3   Mean_liking_Post   786 non-null    float64 \n",
      " 4   IFGr_IFGr          628 non-null    float64 \n",
      " 5   IFGl_IFGl          736 non-null    float64 \n",
      " 6   TPJr_TPJr          494 non-null    float64 \n",
      " 7   TPJl_TPJl          512 non-null    float64 \n",
      " 8   IFGl_IFGr          754 non-null    float64 \n",
      " 9   IFGr_TPJr          682 non-null    float64 \n",
      " 10  IFGr_TPJl          678 non-null    float64 \n",
      " 11  IFGl_TPJr          758 non-null    float64 \n",
      " 12  IFGl_TPJl          756 non-null    float64 \n",
      " 13  TPJr_TPJl          582 non-null    float64 \n",
      " 14  laughter_group     786 non-null    bool    \n",
      " 15  interaction_group  786 non-null    bool    \n",
      "dtypes: bool(2), category(1), float64(13)\n",
      "memory usage: 88.4+ KB\n"
     ]
    }
   ],
   "source": [
    "all_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data for later use\n",
    "filename_data = data_path + \"/all_LT_data.csv\"\n",
    "all_data.to_csv(filename_data, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 First strategy: eliminate all rows with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 372 entries, IC3_A_1 to NIL9_B_4\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count  Dtype   \n",
      "---  ------             --------------  -----   \n",
      " 0   Age                372 non-null    float64 \n",
      " 1   Gender             372 non-null    category\n",
      " 2   Mean_liking_Pre    372 non-null    float64 \n",
      " 3   Mean_liking_Post   372 non-null    float64 \n",
      " 4   IFGr_IFGr          372 non-null    float64 \n",
      " 5   IFGl_IFGl          372 non-null    float64 \n",
      " 6   TPJr_TPJr          372 non-null    float64 \n",
      " 7   TPJl_TPJl          372 non-null    float64 \n",
      " 8   IFGl_IFGr          372 non-null    float64 \n",
      " 9   IFGr_TPJr          372 non-null    float64 \n",
      " 10  IFGr_TPJl          372 non-null    float64 \n",
      " 11  IFGl_TPJr          372 non-null    float64 \n",
      " 12  IFGl_TPJl          372 non-null    float64 \n",
      " 13  TPJr_TPJl          372 non-null    float64 \n",
      " 14  laughter_group     372 non-null    bool    \n",
      " 15  interaction_group  372 non-null    bool    \n",
      "dtypes: bool(2), category(1), float64(13)\n",
      "memory usage: 41.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Drop rows where any column contains NaN\n",
    "all_data = all_data.dropna(how='any')\n",
    "\n",
    "all_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Mean_liking_Pre</th>\n",
       "      <th>Mean_liking_Post</th>\n",
       "      <th>IFGr_IFGr</th>\n",
       "      <th>IFGl_IFGl</th>\n",
       "      <th>TPJr_TPJr</th>\n",
       "      <th>TPJl_TPJl</th>\n",
       "      <th>IFGl_IFGr</th>\n",
       "      <th>IFGr_TPJr</th>\n",
       "      <th>IFGr_TPJl</th>\n",
       "      <th>IFGl_TPJr</th>\n",
       "      <th>IFGl_TPJl</th>\n",
       "      <th>TPJr_TPJl</th>\n",
       "      <th>laughter_group</th>\n",
       "      <th>interaction_group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combined</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IC3_A_1</th>\n",
       "      <td>22.0</td>\n",
       "      <td>f</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.288269</td>\n",
       "      <td>0.303648</td>\n",
       "      <td>0.193177</td>\n",
       "      <td>0.187955</td>\n",
       "      <td>0.304951</td>\n",
       "      <td>0.227554</td>\n",
       "      <td>0.234536</td>\n",
       "      <td>0.300126</td>\n",
       "      <td>0.295440</td>\n",
       "      <td>0.208585</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IC3_A_2</th>\n",
       "      <td>22.0</td>\n",
       "      <td>f</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.284197</td>\n",
       "      <td>0.228178</td>\n",
       "      <td>0.232146</td>\n",
       "      <td>0.299744</td>\n",
       "      <td>0.327344</td>\n",
       "      <td>0.291087</td>\n",
       "      <td>0.274232</td>\n",
       "      <td>0.291310</td>\n",
       "      <td>0.214959</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IC3_A_3</th>\n",
       "      <td>22.0</td>\n",
       "      <td>f</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.238468</td>\n",
       "      <td>0.342319</td>\n",
       "      <td>0.190864</td>\n",
       "      <td>0.221397</td>\n",
       "      <td>0.263937</td>\n",
       "      <td>0.229090</td>\n",
       "      <td>0.218176</td>\n",
       "      <td>0.258146</td>\n",
       "      <td>0.250088</td>\n",
       "      <td>0.226531</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IC4_A_1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>m</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.348762</td>\n",
       "      <td>0.350074</td>\n",
       "      <td>0.285111</td>\n",
       "      <td>0.224902</td>\n",
       "      <td>0.344359</td>\n",
       "      <td>0.261578</td>\n",
       "      <td>0.217713</td>\n",
       "      <td>0.207882</td>\n",
       "      <td>0.188696</td>\n",
       "      <td>0.253347</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IC4_A_2</th>\n",
       "      <td>21.0</td>\n",
       "      <td>m</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.343636</td>\n",
       "      <td>0.286722</td>\n",
       "      <td>0.221597</td>\n",
       "      <td>0.252993</td>\n",
       "      <td>0.337413</td>\n",
       "      <td>0.335984</td>\n",
       "      <td>0.341463</td>\n",
       "      <td>0.350946</td>\n",
       "      <td>0.324989</td>\n",
       "      <td>0.262662</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Age Gender  Mean_liking_Pre  Mean_liking_Post  IFGr_IFGr  \\\n",
       "combined                                                              \n",
       "IC3_A_1   22.0      f         6.666667          7.000000   0.288269   \n",
       "IC3_A_2   22.0      f         6.666667          7.000000   0.361407   \n",
       "IC3_A_3   22.0      f         6.666667          7.000000   0.238468   \n",
       "IC4_A_1   21.0      m         5.333333          4.333333   0.348762   \n",
       "IC4_A_2   21.0      m         5.333333          4.333333   0.343636   \n",
       "\n",
       "          IFGl_IFGl  TPJr_TPJr  TPJl_TPJl  IFGl_IFGr  IFGr_TPJr  IFGr_TPJl  \\\n",
       "combined                                                                     \n",
       "IC3_A_1    0.303648   0.193177   0.187955   0.304951   0.227554   0.234536   \n",
       "IC3_A_2    0.284197   0.228178   0.232146   0.299744   0.327344   0.291087   \n",
       "IC3_A_3    0.342319   0.190864   0.221397   0.263937   0.229090   0.218176   \n",
       "IC4_A_1    0.350074   0.285111   0.224902   0.344359   0.261578   0.217713   \n",
       "IC4_A_2    0.286722   0.221597   0.252993   0.337413   0.335984   0.341463   \n",
       "\n",
       "          IFGl_TPJr  IFGl_TPJl  TPJr_TPJl  laughter_group  interaction_group  \n",
       "combined                                                                      \n",
       "IC3_A_1    0.300126   0.295440   0.208585           False               True  \n",
       "IC3_A_2    0.274232   0.291310   0.214959           False               True  \n",
       "IC3_A_3    0.258146   0.250088   0.226531           False               True  \n",
       "IC4_A_1    0.207882   0.188696   0.253347           False               True  \n",
       "IC4_A_2    0.350946   0.324989   0.262662           False               True  "
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['IC3_A_1', 'IC3_A_2', 'IC3_A_3', 'IC4_A_1', 'IC4_A_2', 'IC4_A_3',\n",
       "       'IC4_A_4', 'IC6_A_1', 'IC6_A_2', 'IC6_A_3',\n",
       "       ...\n",
       "       'NIL5_B_1', 'NIL5_B_2', 'NIL5_B_3', 'NIL8_B_1', 'NIL8_B_2', 'NIL8_B_3',\n",
       "       'NIL9_B_1', 'NIL9_B_2', 'NIL9_B_3', 'NIL9_B_4'],\n",
       "      dtype='object', name='combined', length=372)"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.index.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential problems in the data:\n",
    "- Many missing values for coherence! How to deal with that? Participant exclusion, channel exclusion or inputation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Auto ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Create test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (297, 16)\n",
      "Test data shape: (75, 16)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "#data = pd.read_csv(filename_data)\n",
    "\n",
    "data = all_data\n",
    "\n",
    "# Shuffle and split the dataset into train and test sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)  # 80% train, 20% test\n",
    "\n",
    "# Check the resulting shapes\n",
    "print(\"Train data shape:\", train_data.shape)\n",
    "print(\"Test data shape:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 AutoGluon regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7468\\4286754749.py:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  model_path = \"Y:\\Documents\\Projects\\LT_machine_learning\\Models\\Liking_post\"  # Replace this with the desired folder path\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"Y:\\Documents\\Projects\\LT_machine_learning\\Models\\Liking_post\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.12.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          12\n",
      "Memory Avail:       18.18 GB / 31.71 GB (57.3%)\n",
      "Disk Space Avail:   6.28 GB / 9.77 GB (64.3%)\n",
      "\tWARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. \n",
      "\tWe recommend a minimum available disk space of 10 GB, and large datasets may require more.\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 500s\n",
      "AutoGluon will save models to \"Y:\\Documents\\Projects\\LT_machine_learning\\Models\\Liking_post\"\n",
      "Train Data Rows:    297\n",
      "Train Data Columns: 15\n",
      "Label Column:       Mean_liking_Post\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (8.0, 2.0, 6.17508, 1.15048)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    18603.88 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('bool', [])     :  2 | ['laughter_group', 'interaction_group']\n",
      "\t\t('category', []) :  1 | ['Gender']\n",
      "\t\t('float', [])    : 12 | ['Age', 'Mean_liking_Pre', 'IFGr_IFGr', 'IFGl_IFGl', 'TPJr_TPJr', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 12 | ['Age', 'Mean_liking_Pre', 'IFGr_IFGr', 'IFGl_IFGl', 'TPJr_TPJr', ...]\n",
      "\t\t('int', ['bool']) :  3 | ['Gender', 'laughter_group', 'interaction_group']\n",
      "\t0.0s = Fit runtime\n",
      "\t15 features in original data used to generate 15 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_percentage_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 237, Val Rows: 60\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 499.94s of the 499.94s of remaining time.\n",
      "\t-0.1104\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 499.64s of the 499.64s of remaining time.\n",
      "\t-0.086\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 499.34s of the 499.34s of remaining time.\n",
      "\t-0.1123\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t0.97s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 497.78s of the 497.78s of remaining time.\n",
      "\t-0.1244\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t0.59s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 496.93s of the 496.93s of remaining time.\n",
      "\t-0.1028\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 492.09s of the 492.09s of remaining time.\n",
      "\t-0.109\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t1.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 490.15s of the 490.15s of remaining time.\n",
      "\t-0.0922\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t0.54s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 484.95s of the 484.95s of remaining time.\n",
      "Metric mean_absolute_percentage_error is not supported by this model - using mean_squared_error instead\n",
      "No improvement since epoch 7: early stopping\n",
      "\t-0.1118\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t1.7s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 482.69s of the 482.69s of remaining time.\n",
      "\t-0.0877\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 480.85s of the 480.84s of remaining time.\n",
      "\t-0.1104\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t1.68s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 478.72s of the 478.72s of remaining time.\n",
      "\t-0.0977\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t1.48s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 473.92s of remaining time.\n",
      "\tEnsemble Weights: {'XGBoost': 0.524, 'KNeighborsDist': 0.286, 'NeuralNetFastAI': 0.143, 'LightGBMLarge': 0.048}\n",
      "\t-0.0803\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 26.99s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1620.1 rows/s (60 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"Y:\\Documents\\Projects\\LT_machine_learning\\Models\\Liking_post\")\n"
     ]
    }
   ],
   "source": [
    "model_path = \"Y:\\Documents\\Projects\\LT_machine_learning\\Models\\Liking_post\"  # Replace this with the desired folder path\n",
    "\n",
    "from autogluon.tabular import TabularPredictor\n",
    "predictor = TabularPredictor(label=\"Mean_liking_Post\",\n",
    "                             eval_metric=\"mean_absolute_percentage_error\", path = model_path).fit(train_data, time_limit=500, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the code if I wanted to pre-set the hyperparameter\n",
    "\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "# Define custom hyperparameters\n",
    "hyperparameters = {\n",
    "    'NN_TORCH': [{}],  # Use the default settings for NN_TORCH\n",
    "    'GBM': [\n",
    "        {'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}},  # Ensure ag_args is a dict\n",
    "        {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0}},\n",
    "    ],\n",
    "    'CAT': [{}],\n",
    "    'XGB': [{}],\n",
    "    'FASTAI': [{}],\n",
    "    'RF': [\n",
    "        {'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}},\n",
    "        {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}},\n",
    "        {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}},\n",
    "    ],\n",
    "    'XT': [\n",
    "        {'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}},\n",
    "        {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}},\n",
    "        {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}},\n",
    "    ],\n",
    "    'KNN': [\n",
    "        {'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}},\n",
    "        {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Now use these hyperparameters when fitting the model\n",
    "predictor = TabularPredictor(label=\"joint_action_performance\",\n",
    "                             eval_metric=\"mean_absolute_percentage_error\").fit(\n",
    "    train_data, time_limit=500, hyperparameters=hyperparameters\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-0.080350</td>\n",
       "      <td>mean_absolute_percentage_error</td>\n",
       "      <td>0.037034</td>\n",
       "      <td>4.013341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067521</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>-0.085980</td>\n",
       "      <td>mean_absolute_percentage_error</td>\n",
       "      <td>0.020038</td>\n",
       "      <td>0.026292</td>\n",
       "      <td>0.020038</td>\n",
       "      <td>0.026292</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-0.087699</td>\n",
       "      <td>mean_absolute_percentage_error</td>\n",
       "      <td>0.003994</td>\n",
       "      <td>0.745207</td>\n",
       "      <td>0.003994</td>\n",
       "      <td>0.745207</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreesMSE</td>\n",
       "      <td>-0.092245</td>\n",
       "      <td>mean_absolute_percentage_error</td>\n",
       "      <td>0.043147</td>\n",
       "      <td>0.539078</td>\n",
       "      <td>0.043147</td>\n",
       "      <td>0.539078</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>-0.097686</td>\n",
       "      <td>mean_absolute_percentage_error</td>\n",
       "      <td>0.006003</td>\n",
       "      <td>1.475219</td>\n",
       "      <td>0.006003</td>\n",
       "      <td>1.475219</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestMSE</td>\n",
       "      <td>-0.102782</td>\n",
       "      <td>mean_absolute_percentage_error</td>\n",
       "      <td>0.052939</td>\n",
       "      <td>0.523771</td>\n",
       "      <td>0.052939</td>\n",
       "      <td>0.523771</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-0.108962</td>\n",
       "      <td>mean_absolute_percentage_error</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>1.163818</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>1.163818</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>-0.110363</td>\n",
       "      <td>mean_absolute_percentage_error</td>\n",
       "      <td>0.021760</td>\n",
       "      <td>0.032705</td>\n",
       "      <td>0.021760</td>\n",
       "      <td>0.032705</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>-0.110431</td>\n",
       "      <td>mean_absolute_percentage_error</td>\n",
       "      <td>0.004547</td>\n",
       "      <td>1.682604</td>\n",
       "      <td>0.004547</td>\n",
       "      <td>1.682604</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>-0.111833</td>\n",
       "      <td>mean_absolute_percentage_error</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>1.699102</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>1.699102</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>-0.112328</td>\n",
       "      <td>mean_absolute_percentage_error</td>\n",
       "      <td>0.003996</td>\n",
       "      <td>0.971120</td>\n",
       "      <td>0.003996</td>\n",
       "      <td>0.971120</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>-0.124389</td>\n",
       "      <td>mean_absolute_percentage_error</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>0.589710</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>0.589710</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_val                     eval_metric  \\\n",
       "0   WeightedEnsemble_L2  -0.080350  mean_absolute_percentage_error   \n",
       "1        KNeighborsDist  -0.085980  mean_absolute_percentage_error   \n",
       "2               XGBoost  -0.087699  mean_absolute_percentage_error   \n",
       "3         ExtraTreesMSE  -0.092245  mean_absolute_percentage_error   \n",
       "4         LightGBMLarge  -0.097686  mean_absolute_percentage_error   \n",
       "5       RandomForestMSE  -0.102782  mean_absolute_percentage_error   \n",
       "6              CatBoost  -0.108962  mean_absolute_percentage_error   \n",
       "7        KNeighborsUnif  -0.110363  mean_absolute_percentage_error   \n",
       "8        NeuralNetTorch  -0.110431  mean_absolute_percentage_error   \n",
       "9       NeuralNetFastAI  -0.111833  mean_absolute_percentage_error   \n",
       "10           LightGBMXT  -0.112328  mean_absolute_percentage_error   \n",
       "11             LightGBM  -0.124389  mean_absolute_percentage_error   \n",
       "\n",
       "    pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  \\\n",
       "0        0.037034  4.013341                0.000000           0.067521   \n",
       "1        0.020038  0.026292                0.020038           0.026292   \n",
       "2        0.003994  0.745207                0.003994           0.745207   \n",
       "3        0.043147  0.539078                0.043147           0.539078   \n",
       "4        0.006003  1.475219                0.006003           1.475219   \n",
       "5        0.052939  0.523771                0.052939           0.523771   \n",
       "6        0.000968  1.163818                0.000968           1.163818   \n",
       "7        0.021760  0.032705                0.021760           0.032705   \n",
       "8        0.004547  1.682604                0.004547           1.682604   \n",
       "9        0.006999  1.699102                0.006999           1.699102   \n",
       "10       0.003996  0.971120                0.003996           0.971120   \n",
       "11       0.004001  0.589710                0.004001           0.589710   \n",
       "\n",
       "    stack_level  can_infer  fit_order  \n",
       "0             2       True         12  \n",
       "1             1       True          2  \n",
       "2             1       True          9  \n",
       "3             1       True          7  \n",
       "4             1       True         11  \n",
       "5             1       True          5  \n",
       "6             1       True          6  \n",
       "7             1       True          1  \n",
       "8             1       True         10  \n",
       "9             1       True          8  \n",
       "10            1       True          3  \n",
       "11            1       True          4  "
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "pred = TabularPredictor.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "combined\n",
       "NIL16_B_2    4.823733\n",
       "IC17_A_1     7.470622\n",
       "IC9_A_3      5.984307\n",
       "NIL10_B_2    6.400978\n",
       "IL6_A_2      5.716728\n",
       "               ...   \n",
       "IL25_A_4     6.316867\n",
       "IC6_B_3      6.856371\n",
       "NIC8_B_1     4.278941\n",
       "NIC21_B_2    6.254253\n",
       "NIL23_B_2    6.346714\n",
       "Name: Mean_liking_Post, Length: 75, dtype: float32"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = pred.predict( test_data, model=\"WeightedEnsemble_L2\" )\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_absolute_percentage_error': -0.09619269072108302,\n",
       " 'root_mean_squared_error': -0.7096959947942022,\n",
       " 'mean_squared_error': -0.5036684050269323,\n",
       " 'mean_absolute_error': -0.5470707257588704,\n",
       " 'r2': 0.5147264577403995,\n",
       " 'pearsonr': 0.7311660230432856,\n",
       " 'median_absolute_error': -0.4890875816345215}"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_data = pred.evaluate_predictions(test_data[\"Mean_liking_Post\"], preds)\n",
    "metrics_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Visualize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Y:\\\\Documents\\\\Projects\\\\LT_machine_learning\\\\Models\\\\Liking_post\\\\ensemble_model.png'"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "predictor = TabularPredictor.load(model_path)\n",
    "path_to_png = predictor.plot_ensemble_model()\n",
    "path_to_png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 15 features using 75 rows with 10 shuffle sets...\n",
      "\t161.88s\t= Expected runtime (16.19s per shuffle set)\n",
      "\t4.21s\t= Actual runtime (Completed 10 of 10 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean_liking_Pre</th>\n",
       "      <td>0.085444</td>\n",
       "      <td>0.015024</td>\n",
       "      <td>1.155762e-08</td>\n",
       "      <td>10</td>\n",
       "      <td>0.100884</td>\n",
       "      <td>0.070005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.020151</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>5.124614e-08</td>\n",
       "      <td>10</td>\n",
       "      <td>0.024469</td>\n",
       "      <td>0.015833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPJr_TPJl</th>\n",
       "      <td>0.002461</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>2.026007e-05</td>\n",
       "      <td>10</td>\n",
       "      <td>0.003540</td>\n",
       "      <td>0.001382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IFGl_TPJl</th>\n",
       "      <td>0.001655</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>1.278493e-02</td>\n",
       "      <td>10</td>\n",
       "      <td>0.003669</td>\n",
       "      <td>-0.000358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interaction_group</th>\n",
       "      <td>0.001526</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>3.471859e-05</td>\n",
       "      <td>10</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>0.000809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laughter_group</th>\n",
       "      <td>0.000697</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>1.457082e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IFGr_TPJl</th>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>5.077457e-02</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001275</td>\n",
       "      <td>-0.000358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IFGr_IFGr</th>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>2.311222e-01</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001870</td>\n",
       "      <td>-0.001155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>3.072876e-01</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>-0.000874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IFGl_IFGl</th>\n",
       "      <td>-0.000437</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>8.560990e-01</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>-0.001694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPJl_TPJl</th>\n",
       "      <td>-0.001389</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>9.974490e-01</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.000161</td>\n",
       "      <td>-0.002617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IFGl_TPJr</th>\n",
       "      <td>-0.001647</td>\n",
       "      <td>0.002125</td>\n",
       "      <td>9.816194e-01</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>-0.003831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IFGr_TPJr</th>\n",
       "      <td>-0.001789</td>\n",
       "      <td>0.001376</td>\n",
       "      <td>9.986882e-01</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.000376</td>\n",
       "      <td>-0.003203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IFGl_IFGr</th>\n",
       "      <td>-0.001964</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>9.999975e-01</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.001300</td>\n",
       "      <td>-0.002628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPJr_TPJr</th>\n",
       "      <td>-0.003061</td>\n",
       "      <td>0.001956</td>\n",
       "      <td>9.996034e-01</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.001051</td>\n",
       "      <td>-0.005071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   importance    stddev       p_value   n  p99_high   p99_low\n",
       "Mean_liking_Pre      0.085444  0.015024  1.155762e-08  10  0.100884  0.070005\n",
       "Age                  0.020151  0.004202  5.124614e-08  10  0.024469  0.015833\n",
       "TPJr_TPJl            0.002461  0.001050  2.026007e-05  10  0.003540  0.001382\n",
       "IFGl_TPJl            0.001655  0.001959  1.278493e-02  10  0.003669 -0.000358\n",
       "interaction_group    0.001526  0.000698  3.471859e-05  10  0.002243  0.000809\n",
       "laughter_group       0.000697  0.000386  1.457082e-04  10  0.001094  0.000300\n",
       "IFGr_TPJl            0.000458  0.000795  5.077457e-02  10  0.001275 -0.000358\n",
       "IFGr_IFGr            0.000357  0.001472  2.311222e-01  10  0.001870 -0.001155\n",
       "Gender               0.000167  0.001013  3.072876e-01  10  0.001208 -0.000874\n",
       "IFGl_IFGl           -0.000437  0.001223  8.560990e-01  10  0.000820 -0.001694\n",
       "TPJl_TPJl           -0.001389  0.001195  9.974490e-01  10 -0.000161 -0.002617\n",
       "IFGl_TPJr           -0.001647  0.002125  9.816194e-01  10  0.000538 -0.003831\n",
       "IFGr_TPJr           -0.001789  0.001376  9.986882e-01  10 -0.000376 -0.003203\n",
       "IFGl_IFGr           -0.001964  0.000646  9.999975e-01  10 -0.001300 -0.002628\n",
       "TPJr_TPJr           -0.003061  0.001956  9.996034e-01  10 -0.001051 -0.005071"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = pred.feature_importance(test_data, model=\"WeightedEnsemble_L2\", num_shuffle_sets=10)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_wifiautogluon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
